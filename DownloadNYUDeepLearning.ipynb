{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pourmand1376/Notebooks/blob/main/DownloadNYUDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0Xw0V6M9Kcn",
        "outputId": "5784e85b-7f78-44ac-812a-cb6394c7d0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytube https://www.youtube.com/playlist?list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F803zDLx9PDT",
        "outputId": "1504bc3a-10f2-44b6-90f4-75d5595d7968"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading playlist...\n",
            "01 – History and resources.mp4 | 261 MB\n",
            " ↳ || 100.0%\n",
            "01L – Gradient descent and the backpropagation algorithm.mp4 | 518 MB\n",
            " ↳ || 100.0%\n",
            "02 – Neural nets rotation and squashing.mp4 | 226 MB\n",
            " ↳ || 100.0%\n",
            "02L – Modules and architectures.mp4 | 422 MB\n",
            " ↳ || 100.0%\n",
            "03 – Tools classification with neural nets PyTorch implementation.mp4 | 195 MB\n",
            " ↳ || 100.0%\n",
            "03L – Parameter sharing recurrent and convolutional nets.mp4 | 781 MB\n",
            " ↳ || 100.0%\n",
            "04L – ConvNet in practice.mp4 | 330 MB\n",
            " ↳ || 100.0%\n",
            "041 – Natural signals properties and the convolution.mp4 | 209 MB\n",
            " ↳ || 100.0%\n",
            "042 – Recurrent neural networks vanilla and gated (LSTM).mp4 | 243 MB\n",
            " ↳ || 100.0%\n",
            "05L – Joint embedding method and latent variable energy based models (LV-EBMs).mp4 | 943 MB\n",
            " ↳ || 100.0%\n",
            "051 – Latent Variable Energy Based Models (LV-EBMs) inference.mp4 | 163 MB\n",
            " ↳ || 100.0%\n",
            "052 – But what are these EBMs used for.mp4 | 57 MB\n",
            " ↳ || 100.0%\n",
            "06L – Latent variable EBMs for structured prediction.mp4 | 837 MB\n",
            " ↳ || 100.0%\n",
            "06 – Latent Variable Energy Based Models (LV-EBMs) training.mp4 | 242 MB\n",
            " ↳ || 100.0%\n",
            "07L – PCA AE K-means Gaussian mixture model sparse coding and intuitive VAE.mp4 | 780 MB\n",
            " ↳ || 100.0%\n",
            "07 – Unsupervised learning autoencoding the targets.mp4 | 183 MB\n",
            " ↳ || 100.0%\n",
            "08L – Self-supervised learning and variational inference.mp4 | 876 MB\n",
            " ↳ || 100.0%\n",
            "08 – From LV-EBM to target prop to (vanilla denoising contractive variational) autoencoder.mp4 | 161 MB\n",
            " ↳ || 100.0%\n",
            "09L – Differentiable associative memories attention and transformers.mp4 | 692 MB\n",
            " ↳ || 100.0%\n",
            "09 – AE DAE and VAE with PyTorch generative adversarial networks (GAN) and code.mp4 | 244 MB\n",
            " ↳ || 100.0%\n",
            "10L – Self-supervised learning in computer vision.mp4 | 160 MB\n",
            " ↳ || 100.0%\n",
            "10 – Self  cross hard  soft attention and the Transformer.mp4 | 209 MB\n",
            " ↳ || 100.0%\n",
            "11L – Speech recognition and Graph Transformer Networks.mp4 | 244 MB\n",
            " ↳ || 100.0%\n",
            "11 – Graph Convolutional Networks (GCNs).mp4 | 249 MB\n",
            " ↳ || 100.0%\n",
            "12L – Low resource machine translation.mp4 | 443 MB\n",
            " ↳ || 100.0%\n",
            "12 – Planning and control.mp4 | 230 MB\n",
            " ↳ || 100.0%\n",
            "13L – Optimisation for Deep Learning.mp4 | 525 MB\n",
            " ↳ || 100.0%\n",
            "13 – The Truck Backer-Upper.mp4 | 214 MB\n",
            " ↳ || 100.0%\n",
            "14L – Lagrangian backpropagation final project winners and Q&A session.mp4 | 504 MB\n",
            " ↳ || 100.0%\n",
            "14 – Prediction and Planning Under Uncertainty.mp4 | 216 MB\n",
            " ↳ || 100.0%\n",
            "AI2S Xmas Seminar - Dr Alfredo Canziani (NYU) - Energy-Based Self-Supervised Learning.mp4 | 860 MB\n",
            " ↳ || 100.0%\n",
            "09P – Contrastive joint embedding methods (JEMs) for self-supervised learning (SSL).mp4 | 216 MB\n",
            " ↳ || 100.0%\n",
            "10P – Non-contrastive joint embedding methods (JEMs) for self-supervised learning (SSL).mp4 | 274 MB\n",
            " ↳ || 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytM-cWybHCI1",
        "outputId": "b14542e2-d8f5-4fd8-8708-b0546256c621"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25G\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all files are saved in a folder called NYU ... \n",
        "# yours might be different\n",
        "!zip -r NYU.zip 'NYU Deep Learning SP21'"
      ],
      "metadata": {
        "id": "BUyzFnuD9YLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c4c67d-0201-4df1-a43d-32927c4c6189"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: NYU Deep Learning SP21/ (stored 0%)\n",
            "  adding: NYU Deep Learning SP21/042 – Recurrent neural networks vanilla and gated (LSTM).mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/052 – But what are these EBMs used for.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/14L – Lagrangian backpropagation final project winners and Q&A session.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/11 – Graph Convolutional Networks (GCNs).mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/051 – Latent Variable Energy Based Models (LV-EBMs) inference.mp4 (deflated 4%)\n",
            "  adding: NYU Deep Learning SP21/05L – Joint embedding method and latent variable energy based models (LV-EBMs).mp4 (deflated 0%)\n",
            "  adding: NYU Deep Learning SP21/02L – Modules and architectures.mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/01 – History and resources.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/10P – Non-contrastive joint embedding methods (JEMs) for self-supervised learning (SSL).mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/06 – Latent Variable Energy Based Models (LV-EBMs) training.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/06L – Latent variable EBMs for structured prediction.mp4 (deflated 0%)\n",
            "  adding: NYU Deep Learning SP21/13 – The Truck Backer-Upper.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/AI2S Xmas Seminar - Dr Alfredo Canziani (NYU) - Energy-Based Self-Supervised Learning.mp4 (deflated 4%)\n",
            "  adding: NYU Deep Learning SP21/01L – Gradient descent and the backpropagation algorithm.mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/12 – Planning and control.mp4 (deflated 4%)\n",
            "  adding: NYU Deep Learning SP21/03 – Tools classification with neural nets PyTorch implementation.mp4 (deflated 4%)\n",
            "  adding: NYU Deep Learning SP21/041 – Natural signals properties and the convolution.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/03L – Parameter sharing recurrent and convolutional nets.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/07L – PCA AE K-means Gaussian mixture model sparse coding and intuitive VAE.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/10 – Self  cross hard  soft attention and the Transformer.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/09L – Differentiable associative memories attention and transformers.mp4 (deflated 0%)\n",
            "  adding: NYU Deep Learning SP21/02 – Neural nets rotation and squashing.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/04L – ConvNet in practice.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/13L – Optimisation for Deep Learning.mp4 (deflated 1%)\n",
            "  adding: NYU Deep Learning SP21/09 – AE DAE and VAE with PyTorch generative adversarial networks (GAN) and code.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/08L – Self-supervised learning and variational inference.mp4 (deflated 0%)\n",
            "  adding: NYU Deep Learning SP21/10L – Self-supervised learning in computer vision.mp4 (deflated 7%)\n",
            "  adding: NYU Deep Learning SP21/12L – Low resource machine translation.mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/09P – Contrastive joint embedding methods (JEMs) for self-supervised learning (SSL).mp4 (deflated 2%)\n",
            "  adding: NYU Deep Learning SP21/07 – Unsupervised learning autoencoding the targets.mp4 (deflated 3%)\n",
            "  adding: NYU Deep Learning SP21/11L – Speech recognition and Graph Transformer Networks.mp4 (deflated 6%)\n",
            "  adding: NYU Deep Learning SP21/08 – From LV-EBM to target prop to (vanilla denoising contractive variational) autoencoder.mp4 (deflated 5%)\n",
            "  adding: NYU Deep Learning SP21/14 – Prediction and Planning Under Uncertainty.mp4 (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "id": "4XUsdW_jGvbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3504c88-65e6-41c3-9ae9-43d4d3c33a66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 13G\n",
            "drwxr-xr-x 2 root root 4.0K Mar 22 21:01 'NYU Deep Learning SP21'\n",
            "-rw-r--r-- 1 root root  13G Mar 22 21:12  NYU.zip\n",
            "drwxr-xr-x 1 root root 4.0K Mar 21 22:54  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB9ZGzzBK3yQ",
        "outputId": "6f180b32-f4ee-456a-9aa6-8e657bc1bdb9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp NYU.zip /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "QTSjL2xpLrGu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "He6-Wd4KLs5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}